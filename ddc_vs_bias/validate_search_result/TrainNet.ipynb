{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b885e7-09d5-4407-a481-b0de0ec0a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../ciphers'))\n",
    "\n",
    "import speck3264 as speck3264\n",
    "\n",
    "cipher_dict = {\n",
    "    \"speck3264\":speck3264\n",
    "}\n",
    "\n",
    "from DataGenerator import DataGenerator\n",
    "\n",
    "import numpy as np\n",
    "from os import urandom\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.backend import concatenate\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, AveragePooling1D, Conv1D, MaxPooling1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation, MultiHeadAttention\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger\n",
    "from pickle import dump\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "\n",
    "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
    "    res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr)\n",
    "    return res\n",
    "\n",
    "def make_checkpoint(datei):\n",
    "    res = ModelCheckpoint(datei, monitor='val_loss', save_best_only = True)\n",
    "    return res\n",
    "\n",
    "bs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82949ee-bd82-422a-9e42-c2104a961640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_resnet(num_blocks=2, num_filters=32, num_outputs=1, ds=[64, 64], word_size=64, ks=3, depth=5, reg_param=0.0001, final_activation='sigmoid'):\n",
    "    inp = Input(shape=(num_blocks * word_size * 2,));\n",
    "    rs = Reshape((2 * num_blocks, word_size))(inp);\n",
    "    perm = Permute((2,1))(rs);\n",
    "    conv0 = Conv1D(num_filters, kernel_size=1, padding='same', kernel_regularizer=l2(reg_param))(perm);\n",
    "    conv0 = BatchNormalization()(conv0);\n",
    "    conv0 = Activation('relu')(conv0);\n",
    "    shortcut = conv0;\n",
    "    for i in range(depth):\n",
    "        conv1 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(shortcut);\n",
    "        conv1 = BatchNormalization()(conv1);\n",
    "        conv1 = Activation('relu')(conv1);\n",
    "        conv2 = Conv1D(num_filters, kernel_size=ks, padding='same',kernel_regularizer=l2(reg_param))(conv1);\n",
    "        conv2 = BatchNormalization()(conv2);\n",
    "        conv2 = Activation('relu')(conv2);\n",
    "        shortcut = Add()([shortcut, conv2]);\n",
    "    dense = Flatten()(shortcut);\n",
    "    for d in ds:\n",
    "        dense = Dense(d,kernel_regularizer=l2(reg_param))(dense);\n",
    "        dense = BatchNormalization()(dense);\n",
    "        dense = Activation('relu')(dense);\n",
    "    out = Dense(num_outputs, activation=final_activation, kernel_regularizer=l2(reg_param))(dense);\n",
    "    model = Model(inputs=inp, outputs=out);\n",
    "    return(model);\n",
    "\n",
    "def validate_search(index, cipher, num_epochs, num_rounds=5, num_blocks=2, num_dataset=10**7, diff=(0x0040,0), num_filters=32, ds=[64,64], ks=3, depth=1, reg_param=10**-5, loss='mse', wdir=\"./freshly_trained_nets/\"):\n",
    "    strategy = tf.distribute.MirroredStrategy(\n",
    "        devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\"], \n",
    "        cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "    batch_size = bs * strategy.num_replicas_in_sync\n",
    "    \n",
    "    with strategy.scope():\n",
    "        net = make_resnet(num_blocks=num_blocks, num_filters=num_filters, ds=ds, word_size=cipher.WORD_SIZE(), ks=ks, depth=depth, reg_param=reg_param)\n",
    "        net.compile(optimizer='adam', loss=loss, metrics=['acc'])\n",
    "        \n",
    "    training_generator = DataGenerator(cipher, num_dataset, batch_size, num_rounds, diff)\n",
    "    validation_generator = DataGenerator(cipher, num_dataset//10, batch_size, num_rounds, diff)\n",
    "    \n",
    "    check = make_checkpoint(wdir+'best'+str(num_rounds)+'depth'+str(depth)+'_'+str(index)+'.h5')\n",
    "    lr = LearningRateScheduler(cyclic_lr(10,0.002, 0.0001))\n",
    "    log_path = wdir + 'best' + str(num_rounds) + 'depth' + str(depth) + '_' + str(index) + '.log'\n",
    "    csv_logger = CSVLogger(log_path, append=True)\n",
    "    \n",
    "    h = net.fit(training_generator, epochs=num_epochs, validation_data=validation_generator, callbacks=[lr, check, csv_logger])\n",
    "    \n",
    "    print(\"Best validation accuracy: \", np.max(h.history['val_acc']))\n",
    "    with open(log_path, 'a') as log_file: \n",
    "        log_file.write(f\"Best validation accuracy: {np.max(h.history['val_acc'])}\\n\")\n",
    "\n",
    "    test_generator = DataGenerator(cipher, num_dataset//10, batch_size, num_rounds, diff)\n",
    "    \n",
    "    net.load_weights(wdir+'best'+str(num_rounds)+'depth'+str(depth)+'_'+str(index)+'.h5')\n",
    "    test_loss, test_acc = net.evaluate(test_generator)\n",
    "    print(\"Test accuracy: \", test_acc)\n",
    "    with open(log_path, 'a') as log_file:\n",
    "        log_file.write(f\"Test accuracy: {test_acc}\\n\")\n",
    "\n",
    "    return net, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba3ec4-b93b-4036-88f4-b69c678c455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cipher = cipher_dict['speck3264']\n",
    "diff=(0x0040,0x0000)\n",
    "validate_search(index=6, cipher=cipher_dict['speck3264'], num_epochs=50, num_rounds=5, num_blocks=2, num_dataset=10**7, diff=diff, num_filters=32, ds=[64,64], ks=3, depth=10, reg_param=10**-5, loss='mse', wdir=\"./speck3264/00400000/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.6",
   "language": "python",
   "name": "tensorflow26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
